{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-Up Using PySpark!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML('<style>pre { white-space: pre !important; }</style>'))\n",
    "import pyspark as ps\n",
    "from pyspark.sql.functions import year, month\n",
    "from pyspark.sql.functions import mean, stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we initialize a SparkSession in PySpark and set the configuration for Spark, including setting the master to \"local\" (indicating it's running on a single machine), naming the application \"stock\", and configuring some Spark options. If a SparkSession already exists, it gets that session; otherwise, it creates a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/04/12 19:31:11 WARN Utils: Your hostname, Ava resolves to a loopback address: 127.0.1.1; using 172.24.85.192 instead (on interface eth0)\n",
      "24/04/12 19:31:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/12 19:31:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = ps.sql.SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"stock\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read From CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_df(df, n=5):\n",
    "    df.show(n)\n",
    "    print(\"number of rows: \",df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------------+------------------+---------+------------------+\n",
      "|      Date|      Open|      High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+----------+----------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04|213.429998|214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05|214.599998|215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|214.379993|    215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|    211.75|212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08|210.299994|212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "+----------+----------+----------+------------------+------------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "number of rows:  1762\n"
     ]
    }
   ],
   "source": [
    "stocks_df = spark.read.csv(\"stocks.csv\", header=True, inferSchema=True)\n",
    "show_df(stocks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the schema of the data is automatically inferred by PySpark. All data types are double except for the date column, which has a date data type (yyyy-mm-dd) and the Volume column, which has an integer data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening, Closing, and Volume of Records with Opening Price less than 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+\n",
      "|      Open|             Close|   Volume|\n",
      "+----------+------------------+---------+\n",
      "|213.429998|        214.009998|123432400|\n",
      "|214.599998|        214.379993|150476200|\n",
      "|214.379993|        210.969995|138040000|\n",
      "|    211.75|            210.58|119282800|\n",
      "|210.299994|211.98000499999998|111902700|\n",
      "+----------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "number of rows:  1359\n"
     ]
    }
   ],
   "source": [
    "closing_less_than_500 = stocks_df.filter(stocks_df['Close'] < 500)\n",
    "closing_less_than_500_df = closing_less_than_500.select('Open', 'Close', 'Volume')\n",
    "show_df(closing_less_than_500_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening, Closing, and Volume of Records with Opening Price less than 500 are shown in the output. The number of records having the circumstance is 1359 which 5 rows are shown in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Records with Opening Price more than 200 and Closing Price less than 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "|      Date|              Open|      High|       Low|     Close|   Volume|         Adj Close|\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "|2010-01-22|206.78000600000001|207.499996|    197.16|    197.75|220441900|         25.620401|\n",
      "|2010-01-28|        204.930004|205.500004|198.699995|199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29|        201.079996|202.199995|190.250002|192.060003|311488100|         24.883208|\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "\n",
      "number of rows:  3\n"
     ]
    }
   ],
   "source": [
    "opening_more_than_200_closing_less_than_200 = stocks_df.filter((stocks_df['Open'] > 200) & (stocks_df['Close'] < 200))\n",
    "show_df(opening_more_than_200_closing_less_than_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of records with Opening Price more than 200 and Closing Price less than 200 is 3 which are shown in th output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Year Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the year from the date column and add it as a new column to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------------+------------------+---------+------------------+----+\n",
      "|      Date|      Open|      High|               Low|             Close|   Volume|         Adj Close|Year|\n",
      "+----------+----------+----------+------------------+------------------+---------+------------------+----+\n",
      "|2010-01-04|213.429998|214.499996|212.38000099999996|        214.009998|123432400|         27.727039|2010|\n",
      "|2010-01-05|214.599998|215.589994|        213.249994|        214.379993|150476200|27.774976000000002|2010|\n",
      "|2010-01-06|214.379993|    215.23|        210.750004|        210.969995|138040000|27.333178000000004|2010|\n",
      "|2010-01-07|    211.75|212.000006|        209.050005|            210.58|119282800|          27.28265|2010|\n",
      "|2010-01-08|210.299994|212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|2010|\n",
      "+----------+----------+----------+------------------+------------------+---------+------------------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "number of rows:  1762\n"
     ]
    }
   ],
   "source": [
    "stocks_df_without_year = stocks_df.alias(\"stocks_df_without_year\")\n",
    "stocks_df = stocks_df.withColumn('Year', year(stocks_df['Date']))\n",
    "show_df(stocks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Volume for each Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the minimum volume for each year using the groupBy and agg functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year|minVolume|\n",
      "+----+---------+\n",
      "|2015| 13046400|\n",
      "|2013| 41888700|\n",
      "|2014| 14479600|\n",
      "|2012| 43938300|\n",
      "|2016| 11475900|\n",
      "|2010| 39373600|\n",
      "|2011| 44915500|\n",
      "+----+---------+\n",
      "\n",
      "number of rows:  7\n"
     ]
    }
   ],
   "source": [
    "year_min_volume = stocks_df.groupBy('Year').agg({'Volume':'min'})\n",
    "year_min_volume = year_min_volume.withColumnRenamed('min(Volume)', 'minVolume')\n",
    "show_df(year_min_volume, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highest Low Price for each Month and Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the highest low price for each month and year using the groupBy and agg functions like we did for the minimum volume for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+\n",
      "|year|month|            maxLow|\n",
      "+----+-----+------------------+\n",
      "|2012|   10|        665.550026|\n",
      "|2010|    7|        260.300003|\n",
      "|2010|   12|        325.099991|\n",
      "|2015|    2|        131.169998|\n",
      "|2014|    4|        589.799988|\n",
      "|2015|   12|        117.809998|\n",
      "|2016|    7|            103.68|\n",
      "|2016|   11|        111.400002|\n",
      "|2012|    8| 673.5400089999999|\n",
      "|2013|    2|473.24997699999994|\n",
      "|2012|    4| 626.0000150000001|\n",
      "|2012|   12|        585.500023|\n",
      "|2014|   10|        107.209999|\n",
      "|2016|    5|             99.25|\n",
      "|2014|   12|        115.290001|\n",
      "|2013|    9|        503.479988|\n",
      "|2013|   10|        525.110016|\n",
      "|2014|    5|        628.900002|\n",
      "|2016|    2|         96.650002|\n",
      "|2013|   12| 566.4100269999999|\n",
      "|2014|    1|        552.020004|\n",
      "|2010|   11|        316.759987|\n",
      "|2011|    3|        357.750004|\n",
      "|2013|    3|        461.780022|\n",
      "|2014|    8|        102.199997|\n",
      "|2013|    6|447.38999900000005|\n",
      "|2010|    6|        271.499992|\n",
      "|2012|    7| 605.9999849999999|\n",
      "|2012|    9|        699.569977|\n",
      "|2015|    4|        131.149994|\n",
      "|2010|    5|        262.880009|\n",
      "|2015|    8|        117.519997|\n",
      "|2016|    9|        114.040001|\n",
      "|2010|    9|        291.009998|\n",
      "|2011|    2|             360.5|\n",
      "|2011|    4|        350.300007|\n",
      "|2011|   12|        403.490009|\n",
      "|2015|   11|        121.620003|\n",
      "|2011|    8|        392.369995|\n",
      "|2016|   10|        117.449997|\n",
      "|2015|    9|        115.440002|\n",
      "|2013|    7|449.42999299999997|\n",
      "|2014|    9|        102.720001|\n",
      "|2013|    4|        432.069996|\n",
      "|2014|    3| 539.5899730000001|\n",
      "|2015|   10|        119.449997|\n",
      "|2016|    6|         98.959999|\n",
      "|2013|   11|        547.809975|\n",
      "|2011|    5|        346.880009|\n",
      "|2013|    5|        455.810005|\n",
      "|2011|    7|399.67998900000003|\n",
      "|2010|    8|        260.549995|\n",
      "|2016|   12|        116.779999|\n",
      "|2014|    2| 545.6099780000001|\n",
      "|2012|   11|        594.170021|\n",
      "|2016|    1|        102.410004|\n",
      "|2016|    4|111.33000200000001|\n",
      "|2014|    6|        644.470024|\n",
      "|2011|    6|        344.649998|\n",
      "|2010|   10|        314.289997|\n",
      "|2015|    3|        128.320007|\n",
      "|2010|    2|        202.000004|\n",
      "|2010|    3|        234.459999|\n",
      "|2011|   11|        401.560005|\n",
      "|2012|    1|453.07002300000005|\n",
      "|2015|    7|        130.699997|\n",
      "|2012|    2|        535.700005|\n",
      "|2014|   11|        118.050003|\n",
      "|2015|    6|        130.050003|\n",
      "|2010|    4|268.19001000000003|\n",
      "|2012|    3| 610.3099900000001|\n",
      "|2011|   10|        415.990002|\n",
      "|2012|    5| 581.2300190000001|\n",
      "|2013|    1| 541.6300200000001|\n",
      "|2013|    8|             504.0|\n",
      "|2016|    8|        109.209999|\n",
      "|2015|    1|        116.849998|\n",
      "|2011|    1|        344.440006|\n",
      "|2015|    5|        131.399994|\n",
      "|2010|    1|        213.249994|\n",
      "|2012|    6|        583.100021|\n",
      "|2011|    9|        412.000004|\n",
      "|2014|    7|             98.25|\n",
      "|2016|    3|        108.879997|\n",
      "+----+-----+------------------+\n",
      "\n",
      "number of rows:  84\n"
     ]
    }
   ],
   "source": [
    "stocks_df_without_month = stocks_df.alias(\"stocks_df_without_month\")\n",
    "stocks_df = stocks_df.withColumn('Month', month(stocks_df['Date']))\n",
    "highest_low_price = stocks_df.groupBy(\"year\", \"month\").agg({'Low':'max'})\n",
    "highest_low_price = highest_low_price.withColumnRenamed('max(Low)', 'maxLow')\n",
    "show_df(highest_low_price, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and STD  of High Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean and standard deviation of the high price are calculated using the mean and stddev functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|        avg(High)|      stddev(High)|\n",
      "+-----------------+------------------+\n",
      "|315.9112880164581|186.89817686485767|\n",
      "+-----------------+------------------+\n",
      "\n",
      "number of rows:  1\n"
     ]
    }
   ],
   "source": [
    "mean_stddev_high_price = stocks_df.select(mean('High'), stddev('High'))\n",
    "show_df(mean_stddev_high_price)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
